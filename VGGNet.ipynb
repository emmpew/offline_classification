{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VGG network implemented the idea of a deeper network and much smaller filter size on each convolutional layer. VGGNet had models of 16 to 19 layers. The convolutional filter size were 3x3 in all layers with a periodic pooling all through the network. It's kind of simple and elegant architecture and was able to get 7.3% error in the imageNet dataset.\n",
    "\n",
    "One of the biggest breakthroughs of the team was finding out that having smaller filters and stacking more of them together created a more effective receptive field. What happens is that 3 convolutional layers each with a filter size of 3x3 has the same receptive field as 1 convolutional layer with filter size of 7x7. The advantages are that the number of total parameters per layer decrease and also there are more non-linearities. \n",
    "\n",
    "Pooling layers after each block of convolutional layers make the representations smaller and more manageable sinces it takes the input and spatially downsamples it. The original VGGNet as well has 3 fully connected layers after the convolutional layers have extracted the relevant features.\n",
    "\n",
    "However, the structure of the original VGGNet was slightly modified specifically due to smaller size of input images. Only two fully connected layer were left, one with 512 hidden nodes and the last one with the 10 nodes for the classes. This reduces the amount of parameters in the whole network. As well, dropout was added to reduce overfitting in neural networks by preventing complex co-adaptations on training data. This randomly drops out a percentage of units in the layer. \n",
    "\n",
    "Batch Norm the earlier layers do not get to shift the its hidden unit values as much because they are constrained to have the same mean and variance. So this makes an easier the job of learning in the later layers. As well, similar to dropout, it adds some noise to each hidden layer's activations even though is a non-intended effect. With all these changes to the VGGNet, the model was reduced to ~15M parameters making it faster to train.\n",
    "\n",
    "The dataset used was the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) which consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The dataset has 10 different classes that are completely mutually exclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers, optimizers\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a neural network, we want to normalize or standardize our data ahead of time as part of the preprocessing step. Both techniques put the data in the same scale. In this case, we will standardize the data which means it will have a mean of zero and standard deviation of 1. This will make the pixels of each image to be close to each other instead of being in a scale from 0 to 255. The relatively large inputs can cascade down through the layers in the network which may cause unbalanced gradients may therefore cause [exploding gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem). Additionally, non-normalized data can significantly decrease the training speed of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train,X_test):\n",
    "    mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "    std = np.std(X_train, axis=(0,1,2,3))\n",
    "    X_train = (X_train-mean)/(std+1e-7)\n",
    "    X_test = (X_test-mean)/(std+1e-7)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train, x_test = normalize(x_train, x_test)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True)  # randomly flip images\n",
    "\n",
    "train_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is helpful to reduce the learning rate as the number of training epochs increases. We reduce the learning rate by a constant factor every few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch):\n",
    "    return learning_rate * (0.5 ** (epoch // lr_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32,32,3)\n",
    "classes = 10\n",
    "weight_decay = 0.0005\n",
    "learning_rate = 0.1\n",
    "lr_decay = 1e-6\n",
    "lr_drop = 20\n",
    "batch_size = 128 \n",
    "epochs = 250\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv2D(64, (3,3),input_shape=input_shape,activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block1_conv1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(64, (3,3),activation='relu',padding='same',name='block1_conv2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2),name='block1_pool'))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(128,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block2_conv1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(128,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block2_conv2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2),name='block2_pool'))\n",
    "\n",
    "# Block 3\n",
    "model.add(Conv2D(256,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block3_conv1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(256,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block3_conv2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(256,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block3_conv3'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2),name='block3_pool'))\n",
    "\n",
    "# Block 4\n",
    "model.add(Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block4_conv1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block4_conv2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block4_conv3'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2),name='block4_pool'))\n",
    "\n",
    "# Block 5\n",
    "model.add(Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block5_conv1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block5_conv2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(512,(3,3),activation='relu',padding='same',kernel_regularizer=regularizers.l2(weight_decay),name='block5_conv3'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D((2,2),name='block5_pool'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(units=512,activation='relu',kernel_regularizer=regularizers.l2(weight_decay),name='fc1')) # only one FCL\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=classes,activation='softmax',name='predictions'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "model.compile(sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 15,001,418\n",
      "Trainable params: 14,991,946\n",
      "Non-trainable params: 9,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits the model on batches with real-time data augmentation:\n",
    "history = model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train) // batch_size, epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('cifar10vgg.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results:\n",
    "\n",
    "loss: 0.2916 - acc: 0.9734 - val_loss: 0.5480 - val_acc: 0.9122\n",
    "\n",
    "The model started converging at around 175 epochs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('cifar10vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize history for accuracy\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coremltools framework easily convert our keras model into coreML model to be able to integrate it to any iOS device. This will allow adding the model to an iPhone and do offline classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Keras version 2.1.5 detected. Last version known to be fully compatible of Keras is 2.1.3 .\n"
     ]
    }
   ],
   "source": [
    "import coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : block1_conv1_input, <keras.engine.topology.InputLayer object at 0x1115b1550>\n",
      "1 : block1_conv1, <keras.layers.convolutional.Conv2D object at 0x1115b1748>\n",
      "2 : block1_conv1__activation__, <keras.layers.core.Activation object at 0x181c56ff60>\n",
      "3 : batch_normalization_29, <keras.layers.normalization.BatchNormalization object at 0x1115b1fd0>\n",
      "4 : block1_pool, <keras.layers.pooling.MaxPooling2D object at 0x11181fef0>\n",
      "5 : block5_pool, <keras.layers.pooling.MaxPooling2D object at 0x181a0616a0>\n",
      "6 : flatten, <keras.layers.core.Flatten object at 0x181a30cc50>\n",
      "7 : fc1, <keras.layers.core.Dense object at 0x181a30c630>\n",
      "8 : fc1__activation__, <keras.layers.core.Activation object at 0x181c56ff98>\n",
      "9 : batch_normalization_30, <keras.layers.normalization.BatchNormalization object at 0x181a30ca58>\n",
      "10 : predictions, <keras.layers.core.Dense object at 0x181a2cdd30>\n",
      "11 : predictions__activation__, <keras.layers.core.Activation object at 0x181c56ffd0>\n",
      "Saved trained model\n"
     ]
    }
   ],
   "source": [
    "model_name = 'CIFAR10.mlmodel'\n",
    "classes = ['airplane', 'automobile' ,'bird ','cat ','deer ','dog ','frog ','horse ','ship ','truck']\n",
    "coreml_model = coremltools.converters.keras.convert(model, input_names=['image'], image_input_names='image', class_labels=['airplane', 'automobile' ,'bird ','cat ','deer ','dog ','frog ','horse ','ship ','truck'])\n",
    "coreml_model.save(model_name)\n",
    "print('Saved trained model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
